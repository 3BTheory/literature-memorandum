---
layout: post
title: "End-to-End Temporal Action Detection with 1B Parameters Across 1000 Frames. (arXiv:2311.17241v1 [cs.CV])"
tags: ["video","temporal action localization"]
last_modified_at: 2024-02-08 02:16:40 +0900
---

時系列行動検出をend-to-endで学習する方法の提案．E2Eな手法としては初めて特徴量ベースの（＝バックボーンの事前学習済み特徴抽出器を固定して使う）手法を超える性能を叩き出した．

## 基本情報

### 会議・論文誌

[cs.CV updates on arXiv.org](http://arxiv.org/)

### 論文リンク

* http://arxiv.org/abs/2311.17241

### 著者・所属

* Shuming Liu, Chen-Lin Zhang, Chen Zhao, Bernard Ghanem

## 新規性

* メモリー効率が良く10億パラメータまでスケールするE2Eな時系列行動検出モデルを提案
* E2Eな時系列行動検出としては初めて，事前に抽出しておいた特徴量を用いる特徴量ベース行動検出モデルよりも高い性能を達成した

## 手法

* フレーム・ベースの特徴抽出：従来は動画を16フレームのスニペット単位で特徴抽出する方法が主流であった．これに対して，メモリー効率を考慮してスニペットに区切らないフレーム・ベースの方法を採用（単に一つ付きのフレーム系列として3D-CNNなどに入力するということ）．
* 時間的情報アダプター：全体をファインチューニングするのではなく軽量なアダプターモジュールを導入しそのパラメータのみを最適化する．Point-wiseのボトルネック構造が，その中間に時間方向のdepth-wise convとpoint convを挟む形．
* アダプターの配置：メモリー効率を改善しモデルを大規模化するために，勾配がバックボーンの内部を逆伝播しないようアダプターをバックボーンの外部に配置するネットワーク構造を提案．

## 結果

## 議論・コメント

## 関連文献
